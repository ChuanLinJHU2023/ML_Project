{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('cirrhosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Status'] = train_data['Status'].map({'D': 1, 'C': 0, 'CL': 0})\n",
    "le = LabelEncoder()\n",
    "train_data['Sex'] = le.fit_transform(train_data['Sex'])\n",
    "train_data['Drug'] = train_data['Drug'].map({'Placebo':0, 'penicillamine':1})\n",
    "categorical_cols = ['Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n",
    "for col in categorical_cols:\n",
    "    train_data[col] = train_data[col].map({'Y': 1, 'N': 0, 'S': 0.5}).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "N_Days             0\n",
       "Status             0\n",
       "Drug             264\n",
       "Age                0\n",
       "Sex                0\n",
       "Ascites          106\n",
       "Hepatomegaly     106\n",
       "Spiders          106\n",
       "Edema              0\n",
       "Bilirubin          0\n",
       "Cholesterol      134\n",
       "Albumin            0\n",
       "Copper           108\n",
       "Alk_Phos         106\n",
       "SGOT             106\n",
       "Tryglicerides    136\n",
       "Platelets         11\n",
       "Prothrombin        2\n",
       "Stage              6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    scaler = StandardScaler()\n",
    "    num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # cat_cols = train_data.select_dtypes(include=['object']).columns\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_val[num_cols] = scaler.fit_transform(X_val[num_cols])\n",
    "    sum = 0\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)     \n",
    "        y_pred = model.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        sum += accuracy\n",
    "        \n",
    "        print(f\"{name} Results: {accuracy:.4f}\")\n",
    "    print(f\"Average Accuracy: {sum/4:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Ignore Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train_data[train_data.notna().all(axis=1)].copy()\n",
    "X = train_clean.drop(['ID', 'Status'], axis=1)\n",
    "y = train_clean['Status']\n",
    "X_train_clean, X_val_clean, y_train_clean, y_val_clean = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results: 0.7857\n",
      "Gradient Boosting Results: 0.8571\n",
      "Logistic Regression Results: 0.8214\n",
      "XGBoost Results: 0.8571\n",
      "Average Accuracy: 0.8304\n"
     ]
    }
   ],
   "source": [
    "train_model(X_train_clean, y_train_clean, X_val_clean, y_val_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_imputed = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cols = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\n",
    "mode_cols = ['Stage']\n",
    "\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "train_data_imputed[median_cols] = median_imputer.fit_transform(train_data_imputed[median_cols])\n",
    "train_data_imputed[mode_cols] = mode_imputer.fit_transform(train_data_imputed[mode_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = ['Drug', 'Ascites', 'Hepatomegaly', 'Spiders']\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "train_data_imputed[missing_cols] = knn_imputer.fit_transform(train_data_imputed[missing_cols]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results: 0.8452\n",
      "Gradient Boosting Results: 0.8333\n",
      "Logistic Regression Results: 0.8571\n",
      "XGBoost Results: 0.8571\n",
      "Average Accuracy: 0.8482\n"
     ]
    }
   ],
   "source": [
    "X = train_data_imputed.drop(['ID', 'Status'], axis=1)\n",
    "y = train_data_imputed['Status']\n",
    "X_train_imputed, X_val_imputed, y_train_imputed, y_val_imputed = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_model(X_train_imputed, y_train_imputed, X_val_imputed, y_val_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Label Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_label = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_flags = train_data_label.isnull().astype(int).add_suffix('_missing')\n",
    "\n",
    "numeric_cols = ['Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\n",
    "train_data_label[numeric_cols] = train_data_label[numeric_cols].fillna(train_data_label[numeric_cols].median())\n",
    "\n",
    "cat_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Stage']\n",
    "train_data_label[cat_cols] = train_data_label[cat_cols].fillna(train_data_label[cat_cols].mode().iloc[0])\n",
    "\n",
    "train_data_label = pd.concat([train_data_label, missing_flags], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results: 0.8571\n",
      "Gradient Boosting Results: 0.8333\n",
      "Logistic Regression Results: 0.8095\n",
      "XGBoost Results: 0.8690\n",
      "Average Accuracy: 0.8423\n"
     ]
    }
   ],
   "source": [
    "X = train_data_label.drop(['ID', 'Status'], axis=1)\n",
    "y = train_data_label['Status']\n",
    "X_train_label, X_val_label, y_train_label, y_val_label = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_model(X_train_label, y_train_label, X_val_label, y_val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_em = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_algorithm(df, max_iter=50, tol=1e-3):\n",
    "    feature_cols = ['Age', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema',\n",
    "                   'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos',\n",
    "                   'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage']\n",
    "    \n",
    "    df_imputed = df.copy()\n",
    "    numeric_cols = df_imputed.select_dtypes(include=['float64', 'int64']).columns\n",
    "    categorical_cols = df_imputed.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        df_imputed[col] = df_imputed[col].fillna(df_imputed[col].median())\n",
    "    for col in categorical_cols:\n",
    "        df_imputed[col] = df_imputed[col].fillna(df_imputed[col].mode()[0])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    for iteration in range(max_iter):\n",
    "        old_values = df_imputed.copy()\n",
    "        \n",
    "        for col in feature_cols:\n",
    "            mask = df[col].isna()\n",
    "            if mask.any():\n",
    "                X = df_imputed.drop(columns=[col])\n",
    "                y = df_imputed[col]\n",
    "                numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "                if len(numeric_features) > 0:\n",
    "                    X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "                \n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators=100,\n",
    "                    max_depth=5,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2,\n",
    "                    random_state=42\n",
    "                )\n",
    "                model.fit(X[~mask], y[~mask])\n",
    "                df_imputed.loc[mask, col] = model.predict(X[mask])\n",
    "\n",
    "                if col in ['Sex', 'Drug', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Stage']:\n",
    "                    df_imputed[col] = df_imputed[col].round()\n",
    "\n",
    "        numeric_change = np.abs(old_values.select_dtypes(include=['float64', 'int64']) - \n",
    "                              df_imputed.select_dtypes(include=['float64', 'int64'])).max().max()\n",
    "        \n",
    "        if numeric_change < tol:\n",
    "            print(f\"Converged after {iteration + 1} iterations\")\n",
    "            break\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results: 0.8452\n",
      "Gradient Boosting Results: 0.8095\n",
      "Logistic Regression Results: 0.8571\n",
      "XGBoost Results: 0.8571\n",
      "Average Accuracy: 0.8423\n"
     ]
    }
   ],
   "source": [
    "X = train_data_em.drop(['ID', 'Status'], axis=1)\n",
    "y = train_data_em['Status']\n",
    "\n",
    "X_train_em, X_val_em, y_train_em, y_val_em = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_processed = em_algorithm(X_train_em)\n",
    "X_val_processed = em_algorithm(X_val_em)\n",
    "\n",
    "train_model(X_train_processed, y_train_em, X_val_processed, y_val_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Random Imputation + EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_5 = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_cat_missing_label = ['Drug', 'Ascites', 'Hepatomegaly', 'Spiders']\n",
    "rand_num_missing_label = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(df, rand_cat_missing_label, rand_num_missing_label, reference_col='Ascites'):\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    target_missing_idx = df_imputed[df_imputed[reference_col].isna()].index\n",
    "    \n",
    "    for col in rand_cat_missing_label:\n",
    "        valid_data = df_imputed[col].dropna()\n",
    "        value_counts = valid_data.value_counts(normalize=True)\n",
    "        \n",
    "        current_missing = df_imputed.loc[target_missing_idx, col].isna()\n",
    "        current_missing_idx = target_missing_idx[current_missing]\n",
    "        \n",
    "        if len(current_missing_idx) > 0:\n",
    "            random_values = np.random.choice(\n",
    "                value_counts.index,\n",
    "                size=len(current_missing_idx),\n",
    "                p=value_counts.values\n",
    "            )\n",
    "            \n",
    "            df_imputed.loc[current_missing_idx, col] = random_values\n",
    "    \n",
    "    for col in rand_num_missing_label:\n",
    "        valid_data = df_imputed[col].dropna()\n",
    "        median = valid_data.median()\n",
    "        std = valid_data.std()\n",
    "        \n",
    "        current_missing = df_imputed.loc[target_missing_idx, col].isna()\n",
    "        current_missing_idx = target_missing_idx[current_missing]\n",
    "        \n",
    "        if len(current_missing_idx) > 0:\n",
    "            random_values = np.random.normal(median, std, len(current_missing_idx))\n",
    "            \n",
    "            df_imputed.loc[current_missing_idx, col] = random_values\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = impute_missing_data(\n",
    "    train_data_5,\n",
    "    rand_cat_missing_label,\n",
    "    rand_num_missing_label,\n",
    "    reference_col='Ascites'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 4 iterations\n",
      "Random Forest Results: 0.8690\n",
      "Gradient Boosting Results: 0.8333\n",
      "Logistic Regression Results: 0.8452\n",
      "XGBoost Results: 0.8571\n",
      "Average Accuracy: 0.8512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = imputed_df.drop(['ID', 'Status'], axis=1)\n",
    "y = train_data_5['Status']\n",
    "\n",
    "X_train_5, X_val_5, y_train_5, y_val_5 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_processed = em_algorithm(X_train_5)\n",
    "X_val_processed = em_algorithm(X_val_5)\n",
    "\n",
    "train_model(X_train_processed, y_train_5, X_val_processed, y_val_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cirrhosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Status'] = data['Status'].map({'D': 1, 'C': 0, 'CL': 0})\n",
    "le = LabelEncoder()\n",
    "data['Sex'] = le.fit_transform(data['Sex'])\n",
    "data['Drug'] = data['Drug'].map({'Placebo':0, 'penicillamine':1})\n",
    "categorical_cols = ['Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].map({'Y': 1, 'N': 0, 'S': 0.5}).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_flags = data.isnull().astype(int).add_suffix('_missing')\n",
    "missing_flags = missing_flags.drop(['ID_missing', 'N_Days_missing', 'Status_missing', 'Age_missing', 'Sex_missing', 'Edema_missing', 'Bilirubin_missing', 'Albumin_missing'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_cat_missing_label = ['Drug', 'Ascites', 'Hepatomegaly', 'Spiders']\n",
    "rand_num_missing_label = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 5 iterations\n"
     ]
    }
   ],
   "source": [
    "df = impute_missing_data(\n",
    "    data,\n",
    "    rand_cat_missing_label,\n",
    "    rand_num_missing_label,\n",
    "    reference_col='Ascites'\n",
    ")\n",
    "df = em_algorithm(df)\n",
    "data = pd.concat([df, missing_flags], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataModified = data.copy()\n",
    "dataModified['DiagnosedDay'] = dataModified['Age'] - dataModified['N_Days']\n",
    "dataModified['Age_Group'] = pd.cut(\n",
    "    round(dataModified['Age'] / 365.25).astype(\"int16\"),\n",
    "    bins=[19, 29, 39, 49, 59, 69, 99], \n",
    "    labels=[0, 1, 2, 3, 4, 5]\n",
    ").astype('int16')\n",
    "dataModified['BARatio'] = dataModified['Bilirubin'] / dataModified['Albumin']\n",
    "dataModified['CARatio'] = dataModified['Copper'] / dataModified['Albumin']\n",
    "dataModified['RiskScore'] = dataModified['Bilirubin'] + dataModified['Albumin'] - dataModified['Alk_Phos']\n",
    "dataModified['Liver_Complication_Index'] = (dataModified['Ascites'] * dataModified['Hepatomegaly'] * dataModified['Spiders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataModified.to_csv('./train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataModified['BiliRiskScore'] = (\n",
    "    dataModified['Bilirubin'] + \n",
    "    dataModified['SGOT'] * 0.44 + \n",
    "    dataModified['Tryglicerides'] * 0.44 + \n",
    "    dataModified['Copper'] * 0.46\n",
    ")\n",
    "\n",
    "dataModified['BSRatio'] = dataModified['Bilirubin'] / dataModified['SGOT']\n",
    "# dataModified['BSProduct'] = dataModified['Bilirubin'] * dataModified['SGOT']\n",
    "dataModified['BTRatio'] = dataModified['Bilirubin'] / dataModified['Tryglicerides']\n",
    "# dataModified['BTProduct'] = dataModified['Bilirubin'] * dataModified['Tryglicerides']\n",
    "dataModified['BCRatio'] = dataModified['Bilirubin'] / dataModified['Copper']\n",
    "# dataModified['BCProduct'] = dataModified['Bilirubin'] * dataModified['Copper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataModified.to_csv('./train3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
